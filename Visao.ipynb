{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrrnV0DHtkfk"
      },
      "outputs": [],
      "source": [
        "# Instala a biblioteca ultralytics para uso do modelo YOLO\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa a biblioteca OpenCV para manipula√ß√£o de imagens e v√≠deos\n",
        "import cv2\n",
        "\n",
        "# Importa a biblioteca time para medi√ß√µes de tempo e pausas na execu√ß√£o do c√≥digo\n",
        "import time\n",
        "\n",
        "# Importa a biblioteca os para manipula√ß√£o de arquivos e diret√≥rios\n",
        "import os\n",
        "\n",
        "# Ignora avisos desnecess√°rios para evitar polui√ß√£o na sa√≠da do notebook\n",
        "import warnings\n",
        "\n",
        "# Importa o Matplotlib para gera√ß√£o de gr√°ficos e visualiza√ß√µes\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Importa o Seaborn para visualiza√ß√µes estat√≠sticas aprimoradas\n",
        "import seaborn as sns\n",
        "\n",
        "# Permite exibir Markdown no Jupyter Notebook para formata√ß√£o de textos\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Importa a funcionalidade de upload e download de arquivos no Google Colab\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "nhVNRFeArlFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Desativa avisos do MoviePy para evitar mensagens desnecess√°rias no console\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"moviepy\")\n",
        "\n",
        "# Fun√ß√£o para processar imagem ou v√≠deo e aplicar modelo de detec√ß√£o de postura\n",
        "def processar_midia(caminho_entrada, modelo, tipo='video', caminho_saida='/content/saida.mp4'):\n",
        "    # Verifica se o tipo √© v√°lido (imagem ou v√≠deo)\n",
        "    if tipo not in ['imagem', 'video']:\n",
        "        raise ValueError(\"Tipo deve ser 'imagem' ou 'video'.\")\n",
        "\n",
        "    # Inicializa contadores de tempo para cada postura e o background\n",
        "    tempo_deitado = 0\n",
        "    tempo_sentado = 0\n",
        "    tempo_em_pe = 0\n",
        "    tempo_background = 0\n",
        "    tempo_total = 0\n",
        "\n",
        "    # Listas para armazenar informa√ß√µes sobre posturas e transi√ß√µes\n",
        "    posturas_tempo = []\n",
        "    transicoes = []\n",
        "\n",
        "    # Dicion√°rio para armazenar a dura√ß√£o das posturas detectadas\n",
        "    duracoes_posturas = {0: [], 1: [], 2: [], 3: []}  # 0: Deitado, 1: Sentado, 2: Em P√©, 3: Background\n",
        "\n",
        "    # Marca o in√≠cio do tempo de execu√ß√£o do processamento\n",
        "    inicio_execucao = time.time()\n",
        "\n",
        "    # Se for uma imagem, processa apenas um √∫nico quadro\n",
        "    if tipo == 'imagem':\n",
        "        img = cv2.imread(caminho_entrada)  # L√™ a imagem\n",
        "        results = modelo.predict(img, conf=0.1, verbose=False)  # Faz a predi√ß√£o no modelo com confian√ßa m√≠nima de 10%\n",
        "        annotated_img = results[0].plot()  # Desenha as anota√ß√µes na imagem\n",
        "        cv2.imwrite(caminho_saida, annotated_img)  # Salva a imagem processada\n",
        "        return caminho_saida  # Retorna o caminho do arquivo salvo\n",
        "    else:  # Processamento de v√≠deo\n",
        "        cap = cv2.VideoCapture(caminho_entrada)  # Abre o arquivo de v√≠deo\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # Obt√©m a largura do v√≠deo\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # Obt√©m a altura do v√≠deo\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))  # Obt√©m os frames por segundo (FPS)\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Obt√©m o n√∫mero total de quadros\n",
        "\n",
        "        # Define o codec de v√≠deo e cria um objeto para salvar o v√≠deo processado\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "        out = cv2.VideoWriter(caminho_saida, fourcc, fps, (width, height))\n",
        "\n",
        "        # Inicializa vari√°veis para rastrear transi√ß√µes entre posturas\n",
        "        postura_anterior = None\n",
        "        duracao_atual = 0\n",
        "\n",
        "        # Loop para processar cada quadro do v√≠deo\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()  # L√™ um quadro do v√≠deo\n",
        "            if not ret:\n",
        "                break  # Se n√£o houver mais quadros, encerra o loop\n",
        "\n",
        "            # Aplica o modelo ao quadro e obt√©m os resultados\n",
        "            results = modelo.predict(frame, conf=0.1, verbose=False)\n",
        "            annotated_frame = results[0].plot()  # Adiciona anota√ß√µes ao quadro\n",
        "            out.write(annotated_frame)  # Salva o quadro anotado no v√≠deo de sa√≠da\n",
        "\n",
        "            frame_classificado = False  # Flag para verificar se o quadro foi classificado\n",
        "            class_id = 3  # Define o background como padr√£o\n",
        "\n",
        "            # Percorre os resultados para identificar a postura detectada\n",
        "            for result in results:\n",
        "                for box in result.boxes:\n",
        "                    class_id = int(box.cls)  # Obt√©m a classe detectada\n",
        "                    frame_classificado = True  # Marca o quadro como classificado\n",
        "                    break  # Interrompe ap√≥s encontrar a primeira detec√ß√£o v√°lida\n",
        "\n",
        "            # Atualiza contadores de tempo para cada postura\n",
        "            if not frame_classificado:\n",
        "                tempo_background += 1\n",
        "            else:\n",
        "                if class_id == 0:\n",
        "                    tempo_deitado += 1\n",
        "                elif class_id == 1:\n",
        "                    tempo_sentado += 1\n",
        "                elif class_id == 2:\n",
        "                    tempo_em_pe += 1\n",
        "\n",
        "            # Controle de transi√ß√µes e dura√ß√µes das posturas\n",
        "            if postura_anterior is None:\n",
        "                postura_anterior = class_id\n",
        "                duracao_atual = 1\n",
        "            elif postura_anterior == class_id:\n",
        "                duracao_atual += 1\n",
        "            else:\n",
        "                duracoes_posturas[postura_anterior].append(duracao_atual / fps)  # Converte dura√ß√£o para segundos\n",
        "                transicoes.append((postura_anterior, class_id))  # Registra a transi√ß√£o\n",
        "                postura_anterior = class_id\n",
        "                duracao_atual = 1  # Reinicia a dura√ß√£o\n",
        "\n",
        "            tempo_total += 1\n",
        "            posturas_tempo.append(class_id)\n",
        "\n",
        "        # Libera os objetos de captura e escrita de v√≠deo\n",
        "        cap.release()\n",
        "        out.release()\n",
        "\n",
        "        # Registra o tempo de execu√ß√£o\n",
        "        fim_execucao = time.time()\n",
        "        tempo_execucao = fim_execucao - inicio_execucao\n",
        "\n",
        "        # Exibir relat√≥rio de tempo em formato Markdown\n",
        "        relatorio_tabela = f\"\"\"\n",
        "# üìä Relat√≥rio de Tempo (em Segundos)\n",
        "\n",
        "| Categoria      | Tempo (s) | Porcentagem |\n",
        "|---------------|----------|------------|\n",
        "| **Deitado**   | {tempo_deitado / fps:.2f}  | {(tempo_deitado / tempo_total) * 100:.2f}% |\n",
        "| **Sentado**   | {tempo_sentado / fps:.2f}  | {(tempo_sentado / tempo_total) * 100:.2f}% |\n",
        "| **Em P√©**     | {tempo_em_pe / fps:.2f}    | {(tempo_em_pe / tempo_total) * 100:.2f}% |\n",
        "| **Background** | {tempo_background / fps:.2f}  | {(tempo_background / tempo_total) * 100:.2f}% |\n",
        "| **Dura√ß√£o do V√≠deo**  | {total_frames / fps:.2f}  | 100% |\n",
        "| **Tempo de Processamento** | {tempo_execucao:.2f} | - |\n",
        "\"\"\"\n",
        "        display(Markdown(relatorio_tabela))\n",
        "\n",
        "        # Criar gr√°ficos para an√°lise dos dados\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "        # Gr√°fico de pizza para distribui√ß√£o de tempo por postura\n",
        "        labels = ['Deitado', 'Sentado', 'Em P√©', 'Background']\n",
        "        tempos = [tempo_deitado, tempo_sentado, tempo_em_pe, tempo_background]\n",
        "        colors = ['#FF6384', '#36A2EB', '#FFCE56', '#B0B0B0']\n",
        "        axes[0, 0].pie(tempos, labels=labels, autopct='%1.1f%%', colors=colors)\n",
        "        axes[0, 0].set_title('Distribui√ß√£o de Tempos por Posi√ß√£o')\n",
        "\n",
        "        # Gr√°fico KDE para distribui√ß√£o de dura√ß√µes por postura\n",
        "        for class_id, label, color in zip([0, 1, 2], ['Deitado', 'Sentado', 'Em P√©'], ['#FF6384', '#36A2EB', '#FFCE56']):\n",
        "            if duracoes_posturas[class_id]:\n",
        "                sns.kdeplot(duracoes_posturas[class_id], ax=axes[0, 1], fill=True, color=color, label=label, bw_adjust=1.5, clip=(0, None))\n",
        "\n",
        "        axes[0, 1].set_title('Distribui√ß√£o das Dura√ß√µes por Posi√ß√£o')\n",
        "        axes[0, 1].set_xlabel('Dura√ß√£o (s)')\n",
        "        axes[0, 1].set_ylabel('Densidade')\n",
        "        axes[0, 1].legend()\n",
        "        sns.despine(ax=axes[0, 1])\n",
        "\n",
        "        # Histograma de mudan√ßas de postura\n",
        "        transicoes_numericas = [f'{t[0]}‚Üí{t[1]}' for t in transicoes]\n",
        "        sns.histplot(transicoes_numericas, ax=axes[1, 0])\n",
        "        axes[1, 0].set_title('Frequ√™ncia das Mudan√ßas Entre Posturas')\n",
        "        axes[1, 0].set_xlabel('Transi√ß√£o')\n",
        "        sns.despine(ax=axes[1, 0])\n",
        "\n",
        "        fig.delaxes(axes[1, 1])  # Remove espa√ßo vazio\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        return caminho_saida\n"
      ],
      "metadata": {
        "id": "vtOVP_GP1ls-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carrega o modelo YOLO previamente treinado usando o arquivo de pesos \"best.pt\"\n",
        "modelo = YOLO('/content/best.pt')\n",
        "\n",
        "# Aplica o modelo ao v√≠deo \"teste.mp4\" para detectar posturas\n",
        "# O resultado ser√° salvo e processado automaticamente pela fun√ß√£o \"processar_midia\"\n",
        "processar_midia('/content/teste_2.mp4', modelo, tipo='video')"
      ],
      "metadata": {
        "id": "xKM7c7lF2Dqd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}