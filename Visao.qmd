---
title: "Mini Livro: Detec√ß√£o de Posturas com YOLO"
author: "Pedro Caio"
date: "02/25/2025"
lang: "pt-BR"
lightbox:
  match: auto
  effect: zoom
  desc-position: bottom
  loop: true
format:
  html:
    toc: true
    toc-depth: 3
    toc-expand: 1
    toc-title: Sum√°rio
    number-sections: true
    code-fold: true
    code-summary: "Mostrar C√≥digo"
    code-tools: true
    theme:
        light: flatly
        dark: darkly
---

# Introdu√ß√£o

Este mini livro descreve em detalhes a l√≥gica e a implementa√ß√£o de um algoritmo para detec√ß√£o de posturas (deitado, sentado, em p√©, background) utilizando o modelo YOLO (You Only Look Once). Vamos explorar cada linha de c√≥digo, explicando sua fun√ß√£o e a l√≥gica por tr√°s dela.

---

# Importa√ß√£o de Bibliotecas e Ambiente

## Configura√ß√£o Inicial no Google Colab

Este projeto foi desenvolvido para ser executado no **Google Colab**. Para garantir que tudo funcione corretamente, siga os passos abaixo:

1. **Instalar a biblioteca YOLO**

```python
# Instala a biblioteca ultralytics para uso do modelo YOLO
!pip install ultralytics
```

2. **Importar o arquivo de pesos**

Certifique-se de que o arquivo de pesos `best.pt` (modelo previamente treinado) esteja carregado no Colab.

## Importa√ß√£o das Bibliotecas

```python
import cv2  # OpenCV para manipula√ß√£o de imagens e v√≠deos
import time  # Medi√ß√£o de tempo e pausas na execu√ß√£o do c√≥digo
import os  # Manipula√ß√£o de arquivos e diret√≥rios
import warnings  # Ignora avisos desnecess√°rios
import matplotlib.pyplot as plt  # Gera√ß√£o de gr√°ficos
import seaborn as sns  # Visualiza√ß√µes estat√≠sticas avan√ßadas
from IPython.display import display, Markdown  # Exibi√ß√£o de Markdown em notebooks
from google.colab import files  # Upload e download de arquivos no Google Colab
warnings.filterwarnings("ignore", category=UserWarning, module="moviepy")
```

### Explica√ß√£o
- **cv2**: manipula v√≠deos e imagens, permitindo leitura, escrita, e anota√ß√µes visuais.
- **time**: mede dura√ß√µes, essencial para capturar tempos das posturas.
- **os**: gerencia arquivos e diret√≥rios.
- **warnings**: suprime mensagens desnecess√°rias para manter o console limpo.
- **matplotlib**: cria gr√°ficos, como os gr√°ficos de pizza.
- **seaborn**: facilita gr√°ficos estat√≠sticos.
- **IPython.display**: exibe textos formatados em Markdown.
- **google.colab**: manipula arquivos diretamente no Google Colab.

---

# Fun√ß√£o principal: `processar_midia`

## Estrutura e L√≥gica Geral

A fun√ß√£o `processar_midia` √© respons√°vel por processar imagens ou v√≠deos, aplicar o modelo YOLO para detec√ß√£o de posturas e gerar relat√≥rios sobre o tempo gasto em cada postura. Vamos destrinchar cada parte dela.

```python
def processar_midia(caminho_entrada, modelo, tipo='video', caminho_saida='/content/saida.mp4'):
    if tipo not in ['imagem', 'video']:
        raise ValueError("Tipo deve ser 'imagem' ou 'video'.")
```

### Explica√ß√£o
- **caminho_entrada**: Caminho para o arquivo de entrada (imagem ou v√≠deo).
- **modelo**: O modelo YOLO previamente treinado que ser√° usado para detectar posturas.
- **tipo**: Define se o arquivo de entrada √© uma imagem ou um v√≠deo. Caso n√£o seja nem 'imagem' nem 'video', a fun√ß√£o lan√ßa um erro com o `raise ValueError()`.
- **caminho_saida**: Caminho para onde o arquivo processado (com as anota√ß√µes visuais) ser√° salvo.

---

## Inicializando Contadores

Os contadores ser√£o usados para medir o tempo que a pessoa passa em cada postura ao longo do v√≠deo.

```python
    tempo_deitado = 0
    tempo_sentado = 0
    tempo_em_pe = 0
    tempo_background = 0
    tempo_total = 0

    posturas_tempo = []
    transicoes = []
    duracoes_posturas = {0: [], 1: [], 2: [], 3: []}  # 0: Deitado, 1: Sentado, 2: Em P√©, 3: Background
    inicio_execucao = time.time()
```

### Explica√ß√£o
- **tempo_deitado**: Conta quantos frames mostram a pessoa deitada.
- **tempo_sentado**: Conta quantos frames mostram a pessoa sentada.
- **tempo_em_pe**: Conta quantos frames mostram a pessoa em p√©.
- **tempo_background**: Conta quantos frames sem nenhuma detec√ß√£o relevante (background).
- **tempo_total**: N√∫mero total de frames processados.
- **posturas_tempo**: Lista que registra a postura detectada em cada frame, √∫til para an√°lises posteriores.
- **transicoes**: Lista de transi√ß√µes entre posturas, usada para entender mudan√ßas ao longo do v√≠deo.
- **duracoes_posturas**: Um dicion√°rio que armazena a dura√ß√£o de cada postura em segundos.
- **inicio_execucao**: Marca o tempo de in√≠cio da execu√ß√£o, para depois calcular o tempo total gasto no processamento.

---

## Processamento de Imagem

Caso o tipo de m√≠dia seja 'imagem', o c√≥digo processa a imagem individualmente.

```python
    if tipo == 'imagem':
        img = cv2.imread(caminho_entrada)
        results = modelo.predict(img, conf=0.1, verbose=False)
        annotated_img = results[0].plot()
        cv2.imwrite(caminho_saida, annotated_img)
        return caminho_saida
```

### Explica√ß√£o
- **cv2.imread(caminho_entrada)**: L√™ a imagem localizada no caminho especificado.
- **modelo.predict(img, conf=0.1, verbose=False)**: Aplica o modelo YOLO para detectar posturas na imagem.
  - `conf=0.1`: Define a confian√ßa m√≠nima (10%) para considerar uma detec√ß√£o v√°lida.
  - `verbose=False`: Desativa sa√≠das excessivas no console.
- **results[0].plot()**: Desenha as caixas delimitadoras (bounding boxes) ao redor das posturas detectadas.
- **cv2.imwrite(caminho_saida, annotated_img)**: Salva a imagem anotada no caminho especificado.
- **return caminho_saida**: Retorna o caminho do arquivo gerado.

---

## Processamento de V√≠deo

Agora, vamos ver como o c√≥digo processa v√≠deos frame a frame.

```python
    else:
        cap = cv2.VideoCapture(caminho_entrada)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
```

### Explica√ß√£o
- **cv2.VideoCapture(caminho_entrada)**: Carrega o v√≠deo no caminho especificado.
- **cap.get(cv2.CAP_PROP_FRAME_WIDTH)**: Obt√©m a largura dos frames do v√≠deo.
- **cap.get(cv2.CAP_PROP_FRAME_HEIGHT)**: Obt√©m a altura dos frames.
- **cap.get(cv2.CAP_PROP_FPS)**: Recupera o n√∫mero de quadros por segundo (FPS), essencial para converter frames em segundos.
- **cap.get(cv2.CAP_PROP_FRAME_COUNT)**: Conta o n√∫mero total de frames no v√≠deo.


## Defini√ß√£o do Codec e Cria√ß√£o do Objeto de Escrita de V√≠deo

```python
# Define o codec de v√≠deo e cria um objeto para salvar o v√≠deo processado 
fourcc = cv2.VideoWriter_fourcc(*'XVID')
out = cv2.VideoWriter(caminho_saida, fourcc, fps, (width, height))
```

### Explica√ß√£o
- **fourcc**: Define o codec usado para compress√£o do v√≠deo. 
  - `*'XVID'`: Codec Xvid, amplamente suportado e eficiente.
- **cv2.VideoWriter**: Cria um objeto para salvar o v√≠deo processado.
  - **caminho_saida**: Caminho do arquivo de sa√≠da.
  - **fourcc**: Codec para compress√£o.
  - **fps**: Frames por segundo.
  - **(width, height)**: Dimens√µes do v√≠deo.

---

## Controle de Transi√ß√µes

```python
# Inicializa vari√°veis para rastrear transi√ß√µes entre posturas
postura_anterior = None
duracao_atual = 0
```

### Explica√ß√£o
- **postura_anterior**: Armazena a postura do frame anterior para compara√ß√£o.
- **duracao_atual**: Conta quantos frames a postura atual perdura.

---

## Loop de Processamento de Frames

```python
# Loop para processar cada quadro do v√≠deo
while cap.isOpened():
    ret, frame = cap.read()  # L√™ um quadro do v√≠deo
    if not ret:
        break  # Encerra o loop quando n√£o h√° mais quadros
```

### Explica√ß√£o
- **cap.isOpened()**: Verifica se o v√≠deo foi aberto corretamente.
- **cap.read()**: L√™ o pr√≥ximo frame.
- **ret**: Retorna `False` quando os quadros terminam.
- **break**: Encerra o loop ao final do v√≠deo.

---

## Aplica√ß√£o do Modelo YOLO

```python
    # Aplica o modelo ao quadro e obt√©m os resultados
    results = modelo.predict(frame, conf=0.1, verbose=False)
    annotated_frame = results[0].plot()  # Adiciona anota√ß√µes ao quadro
    out.write(annotated_frame)  # Salva o quadro anotado
```

### Explica√ß√£o
- **modelo.predict()**: Aplica YOLO ao frame.
  - **frame**: Quadro atual.
  - **conf=0.1**: Confian√ßa m√≠nima de 10% para detectar posturas.
  - **verbose=False**: Desativa sa√≠das no console.
- **results[0].plot()**: Desenha as caixas delimitadoras (bounding boxes).
- **out.write()**: Grava o quadro anotado no v√≠deo de sa√≠da.

---

## Classifica√ß√£o das Posturas

```python
    frame_classificado = False
    class_id = 3  # Background padr√£o

    for result in results:
        for box in result.boxes:
            class_id = int(box.cls)
            frame_classificado = True
            break
```

### Explica√ß√£o
- **frame_classificado**: Marca se houve alguma detec√ß√£o.
- **class_id = 3**: Assume que o frame √© background por padr√£o.
- **for result in results**: Itera sobre os resultados.
- **int(box.cls)**: Obt√©m a classe detectada.
- **break**: Para ap√≥s a primeira detec√ß√£o v√°lida.

---

## Contagem de Posturas

```python
    if not frame_classificado:
        tempo_background += 1
    else:
        if class_id == 0:
            tempo_deitado += 1
        elif class_id == 1:
            tempo_sentado += 1
        elif class_id == 2:
            tempo_em_pe += 1
```

### Explica√ß√£o
- Atualiza os contadores de tempo para cada postura.
- **tempo_background**: Incrementado caso nenhuma postura seja detectada.
- **class_id == 0**: Postura deitado.
- **class_id == 1**: Postura sentado.
- **class_id == 2**: Postura em p√©.

---

## Controle de Transi√ß√µes

```python
    if postura_anterior is None:
        postura_anterior = class_id
        duracao_atual = 1
    elif postura_anterior == class_id:
        duracao_atual += 1
    else:
        duracoes_posturas[postura_anterior].append(duracao_atual / fps)
        transicoes.append((postura_anterior, class_id))
        postura_anterior = class_id
        duracao_atual = 1
```

### Explica√ß√£o
- **postura_anterior**: Guarda a √∫ltima postura detectada.
- **duracao_atual**: Incrementa enquanto a postura n√£o muda.
- **duracoes_posturas**: Armazena a dura√ß√£o de cada postura em segundos.
- **transicoes**: Registra mudan√ßas de postura.

---

## Finalizando o Processo

```python
    tempo_total += 1
    posturas_tempo.append(class_id)

cap.release()
out.release()
```

### Explica√ß√£o
- **tempo_total**: Contagem total de frames.
- **posturas_tempo**: Lista com a sequ√™ncia de posturas.
- **cap.release()**: Fecha o v√≠deo de entrada.
- **out.release()**: Finaliza e salva o v√≠deo anotado.


---

## Registro do Tempo de Execu√ß√£o

```python
# Registra o tempo de execu√ß√£o
tempo_execucao = fim_execucao - inicio_execucao
```

### Explica√ß√£o
- **fim_execucao**: Marca o momento em que o processamento do v√≠deo √© conclu√≠do.
- **inicio_execucao**: Foi definido antes do loop de processamento.
- **tempo_execucao**: Subtraindo um pelo outro, obtemos o tempo total gasto para processar o v√≠deo.

---

## Gera√ß√£o do Relat√≥rio de Posturas

```python
# Exibir relat√≥rio de tempo em formato Markdown
relatorio_tabela = f"""
# üìä Relat√≥rio de Tempo (em Segundos)

| Categoria      | Tempo (s) | Porcentagem |
|---------------|----------|------------|
| **Deitado**   | {tempo_deitado / fps:.2f}  | {(tempo_deitado / tempo_total) * 100:.2f}% |
| **Sentado**   | {tempo_sentado / fps:.2f}  | {(tempo_sentado / tempo_total) * 100:.2f}% |
| **Em P√©**     | {tempo_em_pe / fps:.2f}    | {(tempo_em_pe / tempo_total) * 100:.2f}% |
| **Background** | {tempo_background / fps:.2f}  | {(tempo_background / tempo_total) * 100:.2f}% |
| **Dura√ß√£o do V√≠deo**  | {total_frames / fps:.2f}  | 100% |
| **Tempo de Processamento** | {tempo_execucao:.2f} | - |
"""
display(Markdown(relatorio_tabela))
```

### Explica√ß√£o
- **relatorio_tabela**: Usa uma string formatada para criar um relat√≥rio em Markdown.
- **tempo_deitado / fps**: Converte frames em segundos.
- **(tempo_deitado / tempo_total) * 100**: Calcula a porcentagem de tempo gasto em cada postura.
- **display(Markdown(...))**: Exibe o relat√≥rio no formato elegante de Markdown.

---

## Visualiza√ß√µes Gr√°ficas

### Gr√°fico de Pizza: Distribui√ß√£o de Posturas

```python
# Gr√°fico de pizza para distribui√ß√£o de tempo por postura
labels = ['Deitado', 'Sentado', 'Em P√©', 'Background']
tempos = [tempo_deitado, tempo_sentado, tempo_em_pe, tempo_background]
colors = ['#FF6384', '#36A2EB', '#FFCE56', '#B0B0B0']

fig, axes = plt.subplots(2, 2, figsize=(12, 10))
axes[0, 0].pie(tempos, labels=labels, autopct='%1.1f%%', colors=colors)
axes[0, 0].set_title('Distribui√ß√£o de Tempos por Posi√ß√£o')
```

### Explica√ß√£o
- **labels**: Nomes das posturas.
- **tempos**: Lista de tempos acumulados em cada postura.
- **colors**: Cores atribu√≠das a cada postura.
- **plt.pie**: Cria o gr√°fico de pizza.
- **autopct='%1.1f%%'**: Exibe as porcentagens diretamente no gr√°fico.

---

### Gr√°fico KDE: Dura√ß√£o das Posturas

```python
# Gr√°fico KDE para distribui√ß√£o de dura√ß√µes por postura
for class_id, label, color in zip([0, 1, 2], ['Deitado', 'Sentado', 'Em P√©'], ['#FF6384', '#36A2EB', '#FFCE56']):
    if duracoes_posturas[class_id]:
        sns.kdeplot(duracoes_posturas[class_id], ax=axes[0, 1], fill=True, color=color, label=label, bw_adjust=1.5, clip=(0, None))

axes[0, 1].set_title('Distribui√ß√£o das Dura√ß√µes por Posi√ß√£o')
axes[0, 1].set_xlabel('Dura√ß√£o (s)')
axes[0, 1].set_ylabel('Densidade')
axes[0, 1].legend()
sns.despine(ax=axes[0, 1])
```

### Explica√ß√£o
- **zip()**: Itera sobre as classes, r√≥tulos e cores simultaneamente.
- **sns.kdeplot**: Cria gr√°ficos de densidade (KDE) para exibir a distribui√ß√£o das dura√ß√µes.
- **bw_adjust=1.5**: Ajusta a suavidade das curvas.

---

### Histograma: Transi√ß√µes entre Posturas

```python
# Histograma de mudan√ßas de postura
transicoes_numericas = [f'{t[0]}‚Üí{t[1]}' for t in transicoes]
sns.histplot(transicoes_numericas, ax=axes[1, 0])
axes[1, 0].set_title('Frequ√™ncia das Mudan√ßas Entre Posturas')
axes[1, 0].set_xlabel('Transi√ß√£o')
sns.despine(ax=axes[1, 0])
```

### Explica√ß√£o
- **transicoes_numericas**: Transforma transi√ß√µes de posturas em strings formatadas.
- **sns.histplot**: Plota um histograma da frequ√™ncia das transi√ß√µes.
- **set_title()**: Define o t√≠tulo do gr√°fico.
- **set_xlabel()**: Adiciona r√≥tulo ao eixo X.

---

## Exibi√ß√£o Final dos Gr√°ficos

```python
# Ajuste final da visualiza√ß√£o
tplt.delaxes(axes[1, 1])  # Remove espa√ßo vazio
plt.tight_layout()
plt.show()
```

### Explica√ß√£o
- **plt.delaxes()**: Remove um gr√°fico vazio para manter o layout limpo.
- **plt.tight_layout()**: Garante que os gr√°ficos n√£o fiquem sobrepostos.
- **plt.show()**: Renderiza os gr√°ficos.

---

Com isso, conclu√≠mos a an√°lise visual e estat√≠stica das posturas detectadas. Podemos agora avan√ßar para interpretar esses resultados e entender como eles podem informar decis√µes pr√°ticas! üöÄ

--- 

# Exemplo de Aplica√ß√£o do Modelo

```python
# Carrega o modelo YOLO previamente treinado usando o arquivo de pesos "best.pt"
modelo = YOLO('/content/best.pt')

# Aplica o modelo ao v√≠deo "teste.mp4" para detectar posturas
# O resultado ser√° salvo e processado automaticamente pela fun√ß√£o "processar_midia"
processar_midia('/content/teste_2.mp4', modelo, tipo='video')
```

_Exemplo de output:_

![Resultado da Detec√ß√£o](git_visao.png)

---

Com isso, conclu√≠mos a an√°lise visual e estat√≠stica das posturas detectadas. Essencialmente, a transi√ß√£o do modelo de classifica√ß√£o para a EDA transforma simples etiquetas ("Deitado", "Sentado") em uma narrativa estat√≠stica sobre o comportamento ao longo do tempo.
